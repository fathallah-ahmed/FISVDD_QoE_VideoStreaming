# Trained Model Artifacts

This directory stores trained FISVDD models and their associated metadata for each dataset.

## ğŸ“ Contents

```
artifacts/
â”œâ”€â”€ LIVE_NFLX_II_fisvdd.joblib   # Model for LIVE-Netflix-II dataset
â””â”€â”€ LFOVIA_QoE_fisvdd.joblib     # Model for LFOVIA QoE dataset
```

## ğŸ’¾ Artifact Structure

Each `.joblib` file contains a dictionary with:

```python
{
    "dataset_name": str,           # e.g., "LFOVIA_QoE"
    "features": List[str],         # Feature names used
    "scaler": StandardScaler,      # Fitted feature scaler
    "sigma": float,                # RBF kernel width
    "threshold": float,            # Anomaly detection threshold
    "model": fisvdd,               # Trained FISVDD model instance
    "config": dict                 # Training configuration
}
```

## ğŸ”„ Generation

Artifacts are automatically created when you train a model:

```bash
python train_fisvdd.py --dataset DATASET_NAME
```

The artifact is saved to: `artifacts/{DATASET_NAME}_fisvdd.joblib`

## ğŸ“¥ Loading Artifacts

```python
import joblib

# Load artifact
artifact = joblib.load("artifacts/LFOVIA_QoE_fisvdd.joblib")

# Extract components
model = artifact["model"]
scaler = artifact["scaler"]
threshold = artifact["threshold"]
features = artifact["features"]

# Make predictions
import numpy as np
from sklearn.preprocessing import StandardScaler

# Preprocess new data
X_raw = ...  # Your raw features
X_scaled = scaler.transform(X_raw)

# Score with model
score, _ = model.score_fcn(X_scaled)
is_anomaly = score > threshold
```

## ğŸ“Š Model Information

| Dataset | Features | Support Vectors | Threshold | File Size |
|---------|----------|-----------------|-----------|-----------|
| LIVE_NFLX_II | 6 | ~55 | -0.0037 | ~100 KB |
| LFOVIA_QoE | 4 | ~30 | -0.0019 | ~80 KB |

## ğŸ”’ Version Control

**Artifacts are NOT version controlled** (.gitignore excludes `*.joblib` files) because:
- They can be regenerated from data
- They vary with each training run
- File size can be large for big datasets

### Sharing Models

If you need to share trained models:

1. **Cloud storage**: Upload to Google Drive, AWS S3, etc.
2. **GitHub Releases**: Attach as release assets
3. **Model registry**: Use MLflow, Weights & Biases, etc.

## ğŸ§¹ Cleaning Artifacts

To remove all trained models:

```bash
# Windows
Remove-Item artifacts\*.joblib

# Linux/Mac
rm artifacts/*.joblib
```

Models can be regenerated by re-running training.

## ğŸš¨ Important Notes

- **Regenerating** a model will overwrite the existing artifact
- **Scaler** is dataset-specific - don't mix scalers across datasets
- **Threshold** should be validated on held-out test data
- **Model performance** may vary slightly between training runs

## ğŸ”§ Artifact Compatibility

Artifacts are compatible across:
- âœ… Same Python version (3.8+)
- âœ… Same scikit-learn version
- âœ… Same joblib version

May have issues with:
- âŒ Major Python version changes (2.x â†’ 3.x)
- âŒ scikit-learn API breaking changes
- âŒ Different operating systems (sometimes)

## ğŸ“š Related

- **Training**: See [train_fisvdd.py](../train_fisvdd.py)
- **Testing**: See [test_fisvdd.py](../test_fisvdd.py)
- **API Usage**: See [app.py](../app.py)
- **Model Details**: See [fisvdd.py](../fisvdd.py)

---

**Tip**: After training, always verify the model works with:
```bash
python test_fisvdd.py --dataset DATASET_NAME
```
